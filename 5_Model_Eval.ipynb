{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Notebook for evaluating models after training on HPC"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Tensorflow version: 2.13.0\n","GPU available, YES\n"]}],"source":["# load keras model and evaluate on valid set\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import json\n","import os\n","from helpers import *\n","print('Tensorflow version: ' + tf.__version__)\n","print(\"GPU\", \"available, YES\" if tf.config.list_physical_devices(\"GPU\") else \"no GPU\")\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-10-24 10:44:00.709983: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n","2023-10-24 10:44:00.710011: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n","2023-10-24 10:44:00.710016: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n","2023-10-24 10:44:00.710759: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n","2023-10-24 10:44:00.710949: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"]}],"source":["# load valid data\n","path = '/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Dataset/valid_tfrecords/'\n","paths = glob.glob(path + '*.tfrecords')\n","valid_dataset = tf.data.TFRecordDataset(paths[6])\n","valid_dataset = valid_dataset.map(decode_tf_records)\n","valid_dataset = valid_dataset.batch(8)\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/HPC_files/logs/20231021-083045_v81\n"]},{"name":"stderr","output_type":"stream","text":["2023-10-24 10:44:01.609870: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["4135/4135 [==============================] - 47s 11ms/step\n","/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/HPC_files/logs/20231024-003559_v812_DS2000_a100\n"]},{"name":"stderr","output_type":"stream","text":["2023-10-24 10:44:50.711264: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["4135/4135 [==============================] - 50s 12ms/step\n","/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/HPC_files/logs/20231021-085301_v82\n"]},{"name":"stderr","output_type":"stream","text":["2023-10-24 10:45:42.257528: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["4135/4135 [==============================] - 46s 11ms/step\n","/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/HPC_files/logs/20231023-231616_v811_DS2000_a100\n"]},{"name":"stderr","output_type":"stream","text":["2023-10-24 10:46:29.784259: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["4135/4135 [==============================] - 47s 11ms/step\n"]}],"source":["# paths to log folders \n","paths = glob.glob('/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/HPC_files/logs/*')\n","\n","for path in paths:\n","    print(path)\n","    # join path and string\n","    model_path = path + '/model.keras'\n","    config_path = path + '/config.json'\n","    \n","    # load model\n","    model =  keras.models.load_model(model_path, compile=False)\n","    # load json config\n","    with open(config_path, 'r') as fp:\n","      config = json.load(fp)\n","\n","    # make dir in logs\n","    save_dir = path + '/__eval/'\n","    if not os.path.exists(save_dir):\n","        os.makedirs(save_dir)\n","\n","    # get one speechfile from dataset\n","    speech_for_predicition = set_1_speechfile(valid_dataset, save_dir, config)\n","    # predict\n","    y_pred_tf = model.predict(speech_for_predicition)\n","    # change shape to (len(audio), 1)\n","    y_pred_np = tf.squeeze(y_pred_tf, axis=-1).numpy()\n","    \n","    # save plot to disk\n","    plt.figure(figsize=(8, 4))\n","    x = np.arange(0, len(y_pred_np)/int(config['sr']), 1/int(config['sr']))\n","    plt.plot(x, y_pred_np)\n","    plt.title('predicted')\n","    plt.xlabel('Time in s')\n","    plt.ylabel('Amplitude')\n","    plt.savefig(save_dir + '/_predicted.png')\n","    plt.close()\n","    \n","    # save audiofile with tensorflow\n","    y_pred_tf = tf.squeeze(y_pred_tf, axis=-1)\n","    audio_tf = tf.audio.encode_wav(y_pred_tf, int(config['sr']))\n","    tf.io.write_file(save_dir + '/_predicted' + '.wav', audio_tf)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"m1_gpu_preprocessing","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
