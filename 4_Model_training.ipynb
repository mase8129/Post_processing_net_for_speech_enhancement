{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tfrecords, define model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    " # TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "print('Tensorflow Version:', tf.__version__)\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "#Tensorboard\n",
    "%load_ext tensorboard\n",
    "\n",
    "\n",
    "# Helper libraries\n",
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "import librosa\n",
    "import librosa.display\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import IPython.display as pd\n",
    "import pprint\n",
    "import datetime        \n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "\n",
    "# Check if the GPU is available (otherwise computing will take a looooonnnnggggg time)\n",
    "print(\"GPU\", \"available (YESS!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load global settings in config-dictionary\n",
    "with open('./MA_CONFIG.json', 'r') as fp:\n",
    "  config = json.load(fp)\n",
    "\n",
    "# define some extra values\n",
    "config['batch_size'] = 8\n",
    "config['shuffle_buffer_size'] = 300\n",
    "config['n_epochs'] = 2\n",
    "config['filter_size'] = 2\n",
    "config['kernel_size'] = 1\n",
    "\n",
    "# print config\n",
    "print(json.dumps(config, indent=4))\n",
    "\n",
    "# save config to disk\n",
    "with open('./MA_CONFIG.json', 'w+') as fp:\n",
    "    json.dump(config, fp, sort_keys=True, indent=4)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load tfrecords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### func for decoding tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autotune for performance\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# decode tfrecords\n",
    "def decode_tf_records(seralized_example):\n",
    "    feature_description = {\n",
    "        \"voicefixer\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"produced\": tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(seralized_example, feature_description)\n",
    "\n",
    "    voicefixer, _ = tf.audio.decode_wav(example[\"voicefixer\"], desired_channels=-1)\n",
    "    produced, _ = tf.audio.decode_wav(example[\"produced\"], desired_channels=-1)\n",
    "\n",
    "    # voicefixer, produced = (\n",
    "    #     tf.squeeze(voicefixer, 1),\n",
    "    #     tf.squeeze(produced, 1),\n",
    "    # )\n",
    "    \n",
    "    return voicefixer, produced\n",
    "\n",
    "def slicing_audio(voicefixer, produced):\n",
    "    # generate random integer between 0 and 10*44100-3*44100\n",
    "    random_int = tf.random.uniform(shape=[], minval=0, maxval=7*44100, dtype=tf.int32)\n",
    "    # slice audio\n",
    "    voicefixer = voicefixer[random_int:random_int+3*44100]\n",
    "    produced = produced[random_int:random_int+3*44100]\n",
    "    return voicefixer, produced\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train tfrecords\n",
    "tfrecords_paths = glob.glob('/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Dataset/train_tfrecords/*.tfrecords')\n",
    "train_dataset = tf.data.TFRecordDataset(tfrecords_paths[:2])\n",
    "train_dataset = train_dataset.map(decode_tf_records, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.map(slicing_audio, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# count elements in train_dataset\n",
    "print(f'Number of elements in train_dataset: {len([d for d in train_dataset])}')\n",
    "\n",
    "# batching and shuffling\n",
    "train_dataset = train_dataset.shuffle(config['shuffle_buffer_size']).batch(config['batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test tfrecords\n",
    "tfrecords_paths = glob.glob('/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Dataset/test_tfrecords/*.tfrecords')\n",
    "test_dataset = tf.data.TFRecordDataset(tfrecords_paths[:1])\n",
    "test_dataset = test_dataset.map(decode_tf_records, num_parallel_calls=AUTOTUNE)\n",
    "test_dataset = test_dataset.map(slicing_audio, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# count elements in test_dataset\n",
    "print(f'Number of elements in test_dataset: {len([d for d in test_dataset])}')\n",
    "\n",
    "# batching and shuffling\n",
    "test_dataset = test_dataset.shuffle(config['shuffle_buffer_size']).batch(config['batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if datasets are loaded correctly\n",
    "for d in train_dataset:\n",
    "    print(d[0].shape)\n",
    "    print(d[1].shape)\n",
    "    break   \n",
    "\n",
    "for d in test_dataset:\n",
    "    print(d[0].shape)\n",
    "    print(d[1].shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # look at some example data from train dataset\n",
    "# wavs = train_dataset.unbatch().as_numpy_iterator()\n",
    "# noisy = []\n",
    "# gt = []\n",
    "\n",
    "# # Setup Subplot\n",
    "# nrows, ncols = 2, 2\n",
    "# fig, ax = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, figsize=(16, 9))\n",
    "\n",
    "\n",
    "# # iterate over dataset\n",
    "# for i, sample in enumerate(wavs):\n",
    "    \n",
    "#     # get the column and row by modulo and remainder\n",
    "#     j = i % ncols\n",
    "#     k = int(i / ncols)\n",
    "    \n",
    "#     # extract noisy and produced speech file from tensors\n",
    "#     wave = sample[0]\n",
    "#     ground_truth = sample[1]\n",
    "        \n",
    "#     # plot files\n",
    "#     librosa.display.waveshow(np.squeeze(wave), x_axis='time', sr=config['sr'], ax=ax[k][j], label='test_file')\n",
    "#     librosa.display.waveshow(np.squeeze(ground_truth), alpha=0.3, x_axis='time', sr=config['sr'], ax=ax[k][j], label='ground_truth')\n",
    "#     ax[k][j].legend()\n",
    "#     ax[k][j].axis('on')\n",
    "#     ax[k][j].set_title('10s speech')  \n",
    "\n",
    "#     # save speech to arrays\n",
    "#     noisy.append(np.squeeze(wave))\n",
    "#     gt.append(np.squeeze(ground_truth))\n",
    "    \n",
    "#     if i+1 == ncols*nrows:\n",
    "#         break\n",
    "    \n",
    "# # adjust whitespace in between subplots        \n",
    "# plt.subplots_adjust(hspace=0.25, wspace=0.15)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # listen to the audio samples\n",
    "# for i in range(len(gt)):\n",
    "#     print(f'----------- {i+1}. speechsnippet ---------------')\n",
    "#     print('')\n",
    "#     print(f'Voicefixer file')\n",
    "#     pd.display(pd.Audio(noisy[i].T, rate=config['sr']))\n",
    "#     print(f'corresponding produced file')\n",
    "#     pd.display(pd.Audio(gt[i].T, rate=config['sr']))\n",
    "#     print('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some values for the model\n",
    "input_shape = (3*44100, 1)\n",
    "output_channels = 1\n",
    "filter_size = config['filter_size']\n",
    "kernel_size = config['kernel_size']\n",
    "# filter_size = 8\n",
    "# kernel_size = 2\n",
    "\n",
    "\n",
    "# build model with 12 layers\n",
    "def build_model(input_shape):\n",
    "\n",
    "    # define model\n",
    "    model = keras.Sequential(name='PostNet_Conv1D')\n",
    "    model.add(keras.Input(shape=input_shape))\n",
    "\n",
    "    # add layer \n",
    "    model.add(keras.layers.Conv1D(filters=filter_size, kernel_size=kernel_size, padding='same'))\n",
    "    model.add(keras.layers.Activation('tanh'))\n",
    "\n",
    "    # Add the remaining Conv1D layers\n",
    "    for _ in range(11):\n",
    "        model.add(keras.layers.Conv1D(filters=filter_size, kernel_size=kernel_size, padding='same'))\n",
    "        model.add(keras.layers.Activation('tanh'))\n",
    "\n",
    "    # Add the final Conv1D layer\n",
    "    model.add(keras.layers.Conv1D(filters=output_channels, kernel_size=1, padding='same'))\n",
    "    model.add(keras.layers.Activation('tanh'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callbacks\n",
    "log_dir = \"./logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "save_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath='./model_checkpoint',\n",
    "    save_best_only=False,\n",
    "    monitor='val_loss',\n",
    "    verbose=0)\n",
    "\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "    log_dir= log_dir,\n",
    "    histogram_freq=1,\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    write_steps_per_second=True,\n",
    "    update_freq='epoch',\n",
    "    profile_batch=2,\n",
    "    embeddings_freq=1)\n",
    "\n",
    "# early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "#     monitor='val_loss',\n",
    "#     patience=5,\n",
    "#     verbose=1)\n",
    "\n",
    "\n",
    "# set speechfile for prediction\n",
    "dataset = test_dataset.unbatch().as_numpy_iterator()\n",
    "speech_for_predicition = []\n",
    "for i, sample in enumerate(dataset):\n",
    "    speech_for_predicition.append(sample[0])\n",
    "    break\n",
    "speech_for_predicition = speech_for_predicition[0]\n",
    "\n",
    "\n",
    "# define custom callback\n",
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    \n",
    "    # define functions to happen during training after each epoch\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        # print(logs) to check metrics\n",
    "        print('---------------------')\n",
    "        print(f'Epoch {epoch+1} Metrics:')\n",
    "        print(logs)\n",
    "        print('---------------------')\n",
    "        print('')\n",
    "        \n",
    "\n",
    "        # save predicted audio file after each epoch to disk\n",
    "        # get audio file from model prediciton\n",
    "        audio = self.model.predict(speech_for_predicition)\n",
    "\n",
    "        # change shape to (len(audio), 1)\n",
    "        audio = tf.squeeze(audio, axis=-1)\n",
    "\n",
    "        # normalize audio with numpy\n",
    "        audio = librosa.util.normalize(audio.numpy())\n",
    "\n",
    "        # save plot to disk\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        x = np.arange(0, len(audio)/44100, 1/44100)\n",
    "        plt.plot(x, audio)\n",
    "        plt.title('Audiofile')\n",
    "        plt.xlabel('Time in s')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.savefig(log_dir + '/_audiofile_epoch' + str(epoch+1) + '.png')\n",
    "        plt.close()\n",
    "\n",
    "        # write audio file to disk (16-bit PCM WAV)\n",
    "        write(log_dir + '/_audiofile_epoch' + str(epoch+1) + '.wav', 44100, audio.astype(np.int32))\n",
    "\n",
    "\n",
    "# save audio files from logs to tf.summary.audio and event files for tensorboard\n",
    "def save_audio_to_summaries():\n",
    "    \n",
    "        # get audio files from logs\n",
    "        fps = glob.glob('./logs/*' + '/_audiofile_epoch*.wav')\n",
    "        paths_audiosummary = log_dir + '/audiosummary/'\n",
    "        \n",
    "        writer = tf.summary.create_file_writer(paths_audiosummary)\n",
    "        with writer.as_default():\n",
    "\n",
    "            # write audio files to one variable (k, audio, channels) = (len(fps), 3*44100, 1) to tf.summary.audio\n",
    "            # save all audio files to one variable\n",
    "\n",
    "            for idx, fp in enumerate(fps):\n",
    "                file = tf.io.read_file(fp)\n",
    "                audio = tf.audio.decode_wav(file)\n",
    "    \n",
    "                # write audio file to tf.summary.audio\n",
    "                tf.summary.audio('audio_' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") , tf.expand_dims(audio[0], 0), int(44100), step=idx, max_outputs=num_epochs)\n",
    "                writer.flush()\n",
    "\n",
    "\n",
    "\n",
    "# get model\n",
    "model = build_model(input_shape = input_shape)\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer = keras.optimizers.Adam(learning_rate=0.03),\n",
    "              loss = tf.keras.losses.MeanAbsolutePercentageError(),\n",
    "              metrics = tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/\n",
    "\n",
    "# fit model\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=config['n_epochs'],\n",
    "                    validation_data=test_dataset,\n",
    "                    callbacks=[save_callback, tensorboard_callback, CustomCallback()])\n",
    "\n",
    "\n",
    "# call def to save audio to summaries\n",
    "save_audio_to_summaries()\n",
    "\n",
    "# save model\n",
    "model.save('./model.h5')\n",
    "\n",
    "# save history\n",
    "with open('./history.json', 'w+') as fp:\n",
    "    json.dump(history.history, fp, sort_keys=True, indent=4)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mse\n",
    "train_mse = history.history['mean_squared_error']\n",
    "eval_mse = history.history['val_mean_squared_error']\n",
    "\n",
    "fig2 = plt.figure()\n",
    "plt.plot(range(config['n_epochs']), train_mse, label='train')\n",
    "plt.plot(range(config['n_epochs']), eval_mse, label='test')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('mse')\n",
    "plt.title('Training with ' \n",
    "                           + str(config['n_epochs'])\n",
    "                           + ' epochs \\n batch-size: '\n",
    "                           + str(config['batch_size']))\n",
    "                     \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstructed_model = keras.models.load_model('./model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Masterarbeit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
