{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tfrecords, define model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.9.1\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "GPU not available :(\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "\n",
    " # TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "print('Tensorflow Version:', tf.__version__)\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "#Tensorboard\n",
    "%load_ext tensorboard\n",
    "\n",
    "\n",
    "# Helper libraries\n",
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "import librosa\n",
    "import librosa.display\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import IPython.display as pd\n",
    "import pprint\n",
    "import datetime        \n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "\n",
    "# Check if the GPU is available (otherwise computing will take a looooonnnnggggg time)\n",
    "print(\"GPU\", \"available (YESS!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Clear any logs from previous runs\n",
    "# !rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"batch_size\": 16,\n",
      "    \"filter_size\": 8,\n",
      "    \"fps_noisy\": \"/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Data/allFiles/noisySpeech\",\n",
      "    \"fps_produced\": \"/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Data/allFiles/producedSpeech\",\n",
      "    \"fps_voicefixer\": \"/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Data/allFiles/voicefixerOutput\",\n",
      "    \"hop_length\": 64,\n",
      "    \"input_shape\": [\n",
      "        441000,\n",
      "        1\n",
      "    ],\n",
      "    \"kernel_size\": 2,\n",
      "    \"n_epochs\": 3,\n",
      "    \"n_fft\": 512,\n",
      "    \"n_mels\": 16,\n",
      "    \"offset\": 6,\n",
      "    \"sample_length\": 20,\n",
      "    \"shuffle_buffer_size\": 300,\n",
      "    \"sr\": 44100,\n",
      "    \"test_dataset_path\": \"../Dataset/test.tfrecord\",\n",
      "    \"train_dataset_path\": \"../Dataset/train.tfrecord\",\n",
      "    \"win_length\": 512\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# load global settings in config-dictionary\n",
    "with open('./MA_CONFIG.json', 'r') as fp:\n",
    "  config = json.load(fp)\n",
    "\n",
    "# define some extra values\n",
    "config['batch_size'] = 16\n",
    "config['shuffle_buffer_size'] = 300\n",
    "config['n_epochs'] = 3\n",
    "config['filter_size'] = 8\n",
    "config['kernel_size'] = 2\n",
    "\n",
    "# print config\n",
    "print(json.dumps(config, indent=4))\n",
    "\n",
    "# save config to disk\n",
    "with open('./MA_CONFIG.json', 'w+') as fp:\n",
    "    json.dump(config, fp, sort_keys=True, indent=4)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load tfrecords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### func for decoding tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autotune for performance\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# decode tfrecords\n",
    "def decode_tf_records(seralized_example):\n",
    "    feature_description = {\n",
    "        \"voicefixer\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"produced\": tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(seralized_example, feature_description)\n",
    "\n",
    "    voicefixer, _ = tf.audio.decode_wav(example[\"voicefixer\"], desired_channels=-1)\n",
    "    produced, _ = tf.audio.decode_wav(example[\"produced\"], desired_channels=-1)\n",
    "\n",
    "    # voicefixer, produced = (\n",
    "    #     tf.squeeze(voicefixer, 1),\n",
    "    #     tf.squeeze(produced, 1),\n",
    "    # )\n",
    "    \n",
    "    return voicefixer, produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in train_dataset: 120\n"
     ]
    }
   ],
   "source": [
    "# load train tfrecords\n",
    "tfrecords_paths = glob.glob('/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Dataset/train_tfrecords/*.tfrecords')\n",
    "train_dataset = tf.data.TFRecordDataset(tfrecords_paths[:2])\n",
    "train_dataset = train_dataset.map(decode_tf_records, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# count elements in train_dataset\n",
    "print(f'Number of elements in train_dataset: {len([d for d in train_dataset])}')\n",
    "\n",
    "# batching and shuffling\n",
    "train_dataset = train_dataset.shuffle(config['shuffle_buffer_size']).batch(config['batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in test_dataset: 60\n"
     ]
    }
   ],
   "source": [
    "# load test tfrecords\n",
    "tfrecords_paths = glob.glob('/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Dataset/test_tfrecords/*.tfrecords')\n",
    "test_dataset = tf.data.TFRecordDataset(tfrecords_paths[:1])\n",
    "test_dataset = test_dataset.map(decode_tf_records, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# count elements in test_dataset\n",
    "print(f'Number of elements in test_dataset: {len([d for d in test_dataset])}')\n",
    "\n",
    "# batching and shuffling\n",
    "test_dataset = test_dataset.shuffle(config['shuffle_buffer_size']).batch(config['batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 441000, 1)\n",
      "(16, 441000, 1)\n",
      "(16, 441000, 1)\n",
      "(16, 441000, 1)\n"
     ]
    }
   ],
   "source": [
    "# check if datasets are loaded correctly\n",
    "for d in train_dataset:\n",
    "    print(d[0].shape)\n",
    "    print(d[1].shape)\n",
    "    break   \n",
    "\n",
    "for d in test_dataset:\n",
    "    print(d[0].shape)\n",
    "    print(d[1].shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # look at some example data from train dataset\n",
    "# wavs = train_dataset.unbatch().as_numpy_iterator()\n",
    "# noisy = []\n",
    "# gt = []\n",
    "\n",
    "# # Setup Subplot\n",
    "# nrows, ncols = 2, 2\n",
    "# fig, ax = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, figsize=(16, 9))\n",
    "\n",
    "\n",
    "# # iterate over dataset\n",
    "# for i, sample in enumerate(wavs):\n",
    "    \n",
    "#     # get the column and row by modulo and remainder\n",
    "#     j = i % ncols\n",
    "#     k = int(i / ncols)\n",
    "    \n",
    "#     # extract noisy and produced speech file from tensors\n",
    "#     wave = sample[0]\n",
    "#     ground_truth = sample[1]\n",
    "        \n",
    "#     # plot files\n",
    "#     librosa.display.waveshow(np.squeeze(wave), x_axis='time', sr=config['sr'], ax=ax[k][j], label='test_file')\n",
    "#     librosa.display.waveshow(np.squeeze(ground_truth), alpha=0.3, x_axis='time', sr=config['sr'], ax=ax[k][j], label='ground_truth')\n",
    "#     ax[k][j].legend()\n",
    "#     ax[k][j].axis('on')\n",
    "#     ax[k][j].set_title('10s speech')  \n",
    "\n",
    "#     # save speech to arrays\n",
    "#     noisy.append(np.squeeze(wave))\n",
    "#     gt.append(np.squeeze(ground_truth))\n",
    "    \n",
    "#     if i+1 == ncols*nrows:\n",
    "#         break\n",
    "    \n",
    "# # adjust whitespace in between subplots        \n",
    "# plt.subplots_adjust(hspace=0.25, wspace=0.15)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # listen to the audio samples\n",
    "# for i in range(len(gt)):\n",
    "#     print(f'----------- {i+1}. speechsnippet ---------------')\n",
    "#     print('')\n",
    "#     print(f'Voicefixer file')\n",
    "#     pd.display(pd.Audio(noisy[i].T, rate=config['sr']))\n",
    "#     print(f'corresponding produced file')\n",
    "#     pd.display(pd.Audio(gt[i].T, rate=config['sr']))\n",
    "#     print('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some values for the model\n",
    "input_shape = (441000, 1)\n",
    "output_channels = 1\n",
    "filter_size = config['filter_size']\n",
    "kernel_size = config['kernel_size']\n",
    "\n",
    "\n",
    "# build model with 12 layers\n",
    "def build_model(input_shape):\n",
    "\n",
    "    # define model\n",
    "    model = keras.Sequential(name='PostNet_Conv1D')\n",
    "    model.add(keras.Input(shape=input_shape))\n",
    "\n",
    "    # add layer \n",
    "    model.add(keras.layers.Conv1D(filters=filter_size, kernel_size=kernel_size, padding='same'))\n",
    "    model.add(keras.layers.Activation('tanh'))\n",
    "\n",
    "    # Add the remaining Conv1D layers\n",
    "    for _ in range(11):\n",
    "        model.add(keras.layers.Conv1D(filters=filter_size, kernel_size=kernel_size, padding='same'))\n",
    "        model.add(keras.layers.Activation('tanh'))\n",
    "\n",
    "    # Add the final Conv1D layer\n",
    "    model.add(keras.layers.Conv1D(filters=output_channels, kernel_size=1, padding='same'))\n",
    "    model.add(keras.layers.Activation('tanh'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"PostNet_Conv1D\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_1235 (Conv1D)        (None, 441000, 8)         24        \n",
      "                                                                 \n",
      " activation_1235 (Activation  (None, 441000, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1236 (Conv1D)        (None, 441000, 8)         136       \n",
      "                                                                 \n",
      " activation_1236 (Activation  (None, 441000, 8)        0         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 12:50:35.406715: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2023-06-09 12:50:35.406947: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n",
      "2023-06-09 12:50:35.408549: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1237 (Conv1D)        (None, 441000, 8)         136       \n",
      "                                                                 \n",
      " activation_1237 (Activation  (None, 441000, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1238 (Conv1D)        (None, 441000, 8)         136       \n",
      "                                                                 \n",
      " activation_1238 (Activation  (None, 441000, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1239 (Conv1D)        (None, 441000, 8)         136       \n",
      "                                                                 \n",
      " activation_1239 (Activation  (None, 441000, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1240 (Conv1D)        (None, 441000, 8)         136       \n",
      "                                                                 \n",
      " activation_1240 (Activation  (None, 441000, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1241 (Conv1D)        (None, 441000, 8)         136       \n",
      "                                                                 \n",
      " activation_1241 (Activation  (None, 441000, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1242 (Conv1D)        (None, 441000, 8)         136       \n",
      "                                                                 \n",
      " activation_1242 (Activation  (None, 441000, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1243 (Conv1D)        (None, 441000, 8)         136       \n",
      "                                                                 \n",
      " activation_1243 (Activation  (None, 441000, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1244 (Conv1D)        (None, 441000, 8)         136       \n",
      "                                                                 \n",
      " activation_1244 (Activation  (None, 441000, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1245 (Conv1D)        (None, 441000, 8)         136       \n",
      "                                                                 \n",
      " activation_1245 (Activation  (None, 441000, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1246 (Conv1D)        (None, 441000, 8)         136       \n",
      "                                                                 \n",
      " activation_1246 (Activation  (None, 441000, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1247 (Conv1D)        (None, 441000, 1)         9         \n",
      "                                                                 \n",
      " activation_1247 (Activation  (None, 441000, 1)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,529\n",
      "Trainable params: 1,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get model\n",
    "model = build_model(input_shape = input_shape)\n",
    "\n",
    "\n",
    "# define callbacks\n",
    "\n",
    "log_dir = \"./logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "\n",
    "\n",
    "save_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath='./model_checkpoint',\n",
    "    save_best_only=False,\n",
    "    monitor='val_loss',\n",
    "    verbose=0)\n",
    "\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "    log_dir= log_dir,\n",
    "    histogram_freq=1,\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    write_steps_per_second=True,\n",
    "    update_freq='epoch',\n",
    "    profile_batch=2,\n",
    "    embeddings_freq=1)\n",
    "\n",
    "\n",
    "\n",
    "# set speechfile for prediction\n",
    "dataset = test_dataset.unbatch().as_numpy_iterator()\n",
    "speech_for_predicition = []\n",
    "for i, sample in enumerate(dataset):\n",
    "    speech_for_predicition.append(sample[0])\n",
    "    break\n",
    "speech_for_predicition = speech_for_predicition[0]\n",
    "\n",
    "\n",
    "# define custom callback\n",
    "class CustomCallback(keras.callbacks.Callback):\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        # print(logs)\n",
    "        print('---------------------')\n",
    "        print(f'Epoch {epoch+1} Metrics:')\n",
    "        print(logs)\n",
    "        print('---------------------')\n",
    "        print('')\n",
    "        \n",
    "\n",
    "        #save audio file to disk\n",
    "\n",
    "        # get audio file from model prediciton\n",
    "        audio = self.model.predict(speech_for_predicition)\n",
    "        \n",
    "        if not tf.is_tensor(audio):\n",
    "          audio = tf.convert_to_tensor(audio)\n",
    "\n",
    "        # change shape to (441000, 1)\n",
    "        audio = tf.squeeze(audio, axis=-1).numpy()\n",
    "\n",
    "        # normalize audio with numpy\n",
    "        audio = librosa.util.normalize(audio)\n",
    "\n",
    "        # save plot    \n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(audio)\n",
    "        plt.savefig(log_dir + '_audiofile_epoch' + str(epoch+1) + '.png')\n",
    "        plt.close()\n",
    "\n",
    "        # write audio file to disk\n",
    "        write(log_dir + '_audiofile_epoch' + str(epoch+1) + '.wav', 44100, audio)\n",
    " \n",
    "\n",
    "        # # convert audio back to tensor\n",
    "        # audio = tf.convert_to_tensor(audio)\n",
    "        # # write audio file to disk\n",
    "        # audio = tf.audio.encode_wav(audio, sample_rate=tf.constant(44100, dtype=tf.int32))\n",
    "        # # write audio file to disk\n",
    "        # tf.io.write_file(log_dir + '_audiofile_epoch' + str(epoch+1) + '.wav', audio, name=None)\n",
    "\n",
    "\n",
    "\n",
    "        #------------------------------------\n",
    "        # # save audio file to tf.summary.audio and event files for tensorboard\n",
    "        # path = log_dir + '/audiosummary'\n",
    "        # writer = tf.summary.create_file_writer(path)\n",
    "        # with writer.as_default():\n",
    "\n",
    "        #     # get audio file from model\n",
    "        #     audio = self.model.output\n",
    "\n",
    "                \n",
    "            # # check if audio is keras tensor\n",
    "            # if tf.keras.backend.is_keras_tensor(audio) == True:\n",
    "            #     print('is keras tensor')\n",
    "\n",
    "\n",
    "        #     # audio.shape=(None, 441000, 1) should be (1, 441000, 1)\n",
    "        #     # change shape to (1, 441000, 1)\n",
    "        #     audio = tf.squeeze(audio, axis=0)\n",
    "        #     audio = tf.expand_dims(audio, axis=0)\n",
    "\n",
    "        #     # # print audio tensor\n",
    "        #     # print(audio)\n",
    "        #     # print(audio.dtype)\n",
    "        #     # print(audio.shape)\n",
    "\n",
    "        #     # write audio file to tf.summary.audio\n",
    "        #     tf.summary.audio('audio_' + str(epoch), audio, int(config['sr']), step=epoch, max_outputs=1)\n",
    "        #     writer.flush()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "          \n",
    "\n",
    "# early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "#     monitor='val_loss',\n",
    "#     patience=5,\n",
    "#     verbose=1)\n",
    "\n",
    "# keras.callbacks.LambdaCallback(\n",
    "#     on_epoch_end = logging_wav)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer = keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss = tf.keras.losses.MeanAbsolutePercentageError(),\n",
    "              metrics = tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "      1/Unknown - 5s 5s/step - loss: 67158.9141 - mean_squared_error: 0.0217"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 18:44:33.090329: I tensorflow/core/profiler/lib/profiler_session.cc:99] Profiler session initializing.\n",
      "2023-06-08 18:44:33.090368: I tensorflow/core/profiler/lib/profiler_session.cc:114] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2/Unknown - 10s 5s/step - loss: 71871.2266 - mean_squared_error: 0.0219"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-08 18:44:37.598538: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2023-06-08 18:44:37.601315: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session tear down.\n",
      "2023-06-08 18:44:37.603770: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./logs/20230608-184054/plugins/profile/2023_06_08_18_44_37\n",
      "\n",
      "2023-06-08 18:44:37.604899: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to ./logs/20230608-184054/plugins/profile/2023_06_08_18_44_37/Mariuss-MBP.trace.json.gz\n",
      "2023-06-08 18:44:37.608106: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./logs/20230608-184054/plugins/profile/2023_06_08_18_44_37\n",
      "\n",
      "2023-06-08 18:44:37.608207: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to ./logs/20230608-184054/plugins/profile/2023_06_08_18_44_37/Mariuss-MBP.memory_profile.json.gz\n",
      "2023-06-08 18:44:37.608734: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./logs/20230608-184054/plugins/profile/2023_06_08_18_44_37\n",
      "Dumped tool data for xplane.pb to ./logs/20230608-184054/plugins/profile/2023_06_08_18_44_37/Mariuss-MBP.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./logs/20230608-184054/plugins/profile/2023_06_08_18_44_37/Mariuss-MBP.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./logs/20230608-184054/plugins/profile/2023_06_08_18_44_37/Mariuss-MBP.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./logs/20230608-184054/plugins/profile/2023_06_08_18_44_37/Mariuss-MBP.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./logs/20230608-184054/plugins/profile/2023_06_08_18_44_37/Mariuss-MBP.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     75/Unknown - 262s 3s/step - loss: 84088.8984 - mean_squared_error: 0.0210"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Epoch 1 Metrics:\n",
      "{'loss': 84088.8984375, 'mean_squared_error': 0.020989101380109787, 'val_loss': 25717.22265625, 'val_mean_squared_error': 0.014231903478503227}\n",
      "---------------------\n",
      "\n",
      "13782/13782 [==============================] - 7s 508us/step\n",
      "75/75 [==============================] - 276s 4s/step - loss: 84088.8984 - mean_squared_error: 0.0210 - val_loss: 25717.2227 - val_mean_squared_error: 0.0142\n",
      "Epoch 2/5\n",
      "75/75 [==============================] - ETA: 0s - loss: 59297.7539 - mean_squared_error: 0.0209"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Epoch 2 Metrics:\n",
      "{'loss': 59297.75390625, 'mean_squared_error': 0.020926039665937424, 'val_loss': 103271.3984375, 'val_mean_squared_error': 0.014425699599087238}\n",
      "---------------------\n",
      "\n",
      "13782/13782 [==============================] - 7s 491us/step\n",
      "75/75 [==============================] - 267s 4s/step - loss: 59297.7539 - mean_squared_error: 0.0209 - val_loss: 103271.3984 - val_mean_squared_error: 0.0144\n",
      "Epoch 3/5\n",
      "75/75 [==============================] - ETA: 0s - loss: 41076.8672 - mean_squared_error: 0.0209"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Epoch 3 Metrics:\n",
      "{'loss': 41076.8671875, 'mean_squared_error': 0.02091315947473049, 'val_loss': 31994.3046875, 'val_mean_squared_error': 0.01437667291611433}\n",
      "---------------------\n",
      "\n",
      "13782/13782 [==============================] - 7s 507us/step\n",
      "75/75 [==============================] - 272s 4s/step - loss: 41076.8672 - mean_squared_error: 0.0209 - val_loss: 31994.3047 - val_mean_squared_error: 0.0144\n",
      "Epoch 4/5\n",
      "75/75 [==============================] - ETA: 0s - loss: 57964.7539 - mean_squared_error: 0.0209"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Epoch 4 Metrics:\n",
      "{'loss': 57964.75390625, 'mean_squared_error': 0.020927349105477333, 'val_loss': 25870.04296875, 'val_mean_squared_error': 0.014391820877790451}\n",
      "---------------------\n",
      "\n",
      "13782/13782 [==============================] - 7s 507us/step\n",
      "75/75 [==============================] - 268s 4s/step - loss: 57964.7539 - mean_squared_error: 0.0209 - val_loss: 25870.0430 - val_mean_squared_error: 0.0144\n",
      "Epoch 5/5\n",
      "75/75 [==============================] - ETA: 0s - loss: 24355.7441 - mean_squared_error: 0.0209"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Epoch 5 Metrics:\n",
      "{'loss': 24355.744140625, 'mean_squared_error': 0.020896360278129578, 'val_loss': 20530.623046875, 'val_mean_squared_error': 0.014158929698169231}\n",
      "---------------------\n",
      "\n",
      "13782/13782 [==============================] - 7s 514us/step\n",
      "75/75 [==============================] - 269s 4s/step - loss: 24355.7441 - mean_squared_error: 0.0209 - val_loss: 20530.6230 - val_mean_squared_error: 0.0142\n"
     ]
    }
   ],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/\n",
    "\n",
    "# fit model\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=config['n_epochs'],\n",
    "                    validation_data=test_dataset,\n",
    "                    callbacks=[save_callback, tensorboard_callback, CustomCallback()])\n",
    "\n",
    "# # save model\n",
    "# model.save('./model.h5')\n",
    "\n",
    "# # save history\n",
    "# with open('./history.json', 'w+') as fp:\n",
    "#     json.dump(history.history, fp, sort_keys=True, indent=4)\n",
    "\n",
    "\n",
    "# %tensorboard --logdir logs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mse\n",
    "train_mse = history.history['mean_squared_error']\n",
    "eval_mse = history.history['val_mean_squared_error']\n",
    "\n",
    "fig2 = plt.figure()\n",
    "plt.plot(range(config['n_epochs']), train_mse, label='train')\n",
    "plt.plot(range(config['n_epochs']), eval_mse, label='test')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('mse')\n",
    "plt.title('Training with ' \n",
    "                           + str(config['n_epochs'])\n",
    "                           + ' epochs \\n batch-size: '\n",
    "                           + str(config['batch_size']))\n",
    "                     \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstructed_model = keras.models.load_model('./model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Masterarbeit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
