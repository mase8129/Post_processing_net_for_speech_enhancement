{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "import librosa\n",
    "import librosa.display\n",
    "import json\n",
    "import tensorflow as tf\n",
    "print('Tensorflow Version:', tf.__version__)\n",
    "import random\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "from IPython.display import Audio\n",
    "import pprint\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write Config file and save as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config file\n",
    "\n",
    "# save global settings in config dict\n",
    "config = {'sr': 44100,\n",
    "          'fps_noisy': '/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Data/allFiles/noisySpeech',\n",
    "          'fps_produced': '/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Data/allFiles/producedSpeech',\n",
    "          'fps_voicefixer': '/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Data/allFiles/voicefixerOutput',\n",
    "          'n_fft': 512,\n",
    "          'hop_length': 64,\n",
    "          'win_length': 512,\n",
    "          'n_mels': 16,\n",
    "          'sample_length': 20,\n",
    "          'offset': 6}\n",
    "\n",
    "# print config\n",
    "print(json.dumps(config, indent=4))\n",
    "\n",
    "# save config to disk\n",
    "with open('./MA_CONFIG.json', 'w+') as fp:\n",
    "    json.dump(config, fp, indent=len(config))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data dict with all labels and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data dictionary\n",
    "\n",
    "noisy_data_path = config['fps_noisy']\n",
    "produced_data_path = config['fps_produced']\n",
    "voicefixer_data_path = config['fps_voicefixer']\n",
    "\n",
    "data = {'label_noisy': [],\n",
    "        'path_noisy': [],\n",
    "        'mic_room_noisy': [],\n",
    "\n",
    "        'label_produced': [],\n",
    "        'path_produced': [],\n",
    "        \n",
    "        'label_voicefixer': [],\n",
    "        'path_voicefixer': [],\n",
    "        'mic_room_voicefixer': []\n",
    "        }\n",
    "\n",
    "\n",
    "# loop through all the noisy speech files and store\n",
    "for i, (dirpath, dirnames, filenames) in enumerate(os.walk(noisy_data_path)):\n",
    "\n",
    "    # load speechfiles and store in dictionary\n",
    "    for f in filenames:\n",
    "        # skip file that doesnt end with \".wav\"\n",
    "        if not f.endswith(\".wav\"):\n",
    "            continue\n",
    " \n",
    "        # get filepath\n",
    "        file_path = os.path.join(dirpath, f)\n",
    " \n",
    "        # store data in dict\n",
    "        # get the speaker and scriptname and store it in 'label'\n",
    "        category = f.split('_')[0:2]\n",
    "        category[0] = category[0] + '_' + category[1]\n",
    "        data['label_noisy'].append(category[0])\n",
    "\n",
    "        # get the room and mic and store it in 'mic_room_xx'\n",
    "        mic_room = f.split('.')[0]\n",
    "        data['mic_room_noisy'].append(mic_room)\n",
    "\n",
    "        # store filepath\n",
    "        data['path_noisy'].append(file_path)\n",
    "\n",
    "\n",
    "# loop through all the produced speech files and store\n",
    "for i, (dirpath, dirnames, filenames) in enumerate(os.walk(produced_data_path)):\n",
    "    #print(f\"Produced Filenames: {filenames}\")\n",
    "\n",
    "    # load speechfiles and store in dictionary\n",
    "    for f in filenames:\n",
    "        # skip file that doesnt end with \".wav\"\n",
    "        if not f.endswith(\".wav\"):\n",
    "            continue\n",
    "\n",
    "        # get filepath\n",
    "        file_path = os.path.join(dirpath, f)\n",
    "\n",
    "        # store data in dict\n",
    "        # get the speaker and scriptname and store it in 'label'\n",
    "        category = f.split('_')[0:2]\n",
    "        category[0] = category[0] + '_' + category[1]\n",
    "        data['label_produced'].append(category[0])\n",
    "        # store filepath\n",
    "        data['path_produced'].append(file_path)\n",
    "\n",
    "\n",
    "# loop through all the voicefixer output speech files and store\n",
    "for i, (dirpath, dirnames, filenames) in enumerate(os.walk(voicefixer_data_path)):\n",
    "    #print(f\"Voicefixer Filenames: {filenames}\")\n",
    "\n",
    "    # load speechfiles and store in dictionary\n",
    "    for f in filenames:\n",
    "        # skip file that doesnt end with \".wav\"\n",
    "        if not f.endswith(\".wav\"):\n",
    "            continue\n",
    "        \n",
    "        # get filepath\n",
    "        file_path = os.path.join(dirpath, f)\n",
    "\n",
    "        # store data in dict\n",
    "        # get the speaker and scriptname and store it in 'label'\n",
    "        category = f.split('_')[0:2]\n",
    "        category[0] = category[0] + '_' + category[1]\n",
    "        data['label_voicefixer'].append(category[0])\n",
    "\n",
    "        # get the room and mic and store it in 'mic_room_xx'\n",
    "        mic_room = f.split('.')[0]\n",
    "        data['mic_room_voicefixer'].append(mic_room)\n",
    "\n",
    "        # store filepath\n",
    "        data['path_voicefixer'].append(file_path)\n",
    "\n",
    "\n",
    "#pprint.pprint(data, depth=2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot 3 corresponding files from all data (noisy, produced, voicefixer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create array and store 3 corresponding pathfiles\n",
    "rand = np.random.randint(len(data['label_produced']))\n",
    "label1 = data['label_produced'][rand]\n",
    "#print(label1)\n",
    "\n",
    "corresponding = []\n",
    "corresponding.append(data[\"path_produced\"][rand])\n",
    "mic = []\n",
    "\n",
    "for count, value in enumerate(data[\"mic_room_noisy\"]):\n",
    "    if label1 in value:\n",
    "        corresponding.append(data[\"path_noisy\"][count])\n",
    "        mic.append(data['mic_room_noisy'][count])\n",
    "        break\n",
    "for count, value in enumerate(data['mic_room_voicefixer']):\n",
    "    if mic[0] in value:\n",
    "        corresponding.append(data[\"path_voicefixer\"][count])\n",
    "        mic.append(data['mic_room_voicefixer'][count])\n",
    "        break\n",
    "\n",
    "\n",
    "pprint.pprint(corresponding, depth=2) \n",
    "\n",
    "\n",
    "# Plot corresponding audiofiles\n",
    "# load files from corresponding list with filepaths\n",
    "audio1, _ = librosa.core.load(corresponding[0], sr= config['sr'])\n",
    "audio2, _ = librosa.core.load(corresponding[1], sr= config['sr'])\n",
    "audio3, _ = librosa.core.load(corresponding[2], sr= config['sr'])\n",
    "\n",
    "# Only plot segment of speech files\n",
    "time_in_sec = 20\n",
    "seg = int(time_in_sec*config['sr'])\n",
    "       \n",
    "# time vector in min\n",
    "t = np.linspace(0, seg, seg)\n",
    "# only plot segment of audio file in samples\n",
    "\n",
    "# setup subplot \n",
    "fig, axs = plt.subplots(3, 1, figsize=(8, 12))\n",
    "axs[0].plot(t[0:seg], audio1[0:seg], c='k')\n",
    "axs[0].set_title(Path(corresponding[0]).parts[-1])\n",
    "axs[1].plot(t[0:seg], audio2[0:seg], c='k')\n",
    "axs[1].set_title(Path(corresponding[1]).parts[-1])\n",
    "axs[2].plot(t[0:seg], audio3[0:seg], c='k')\n",
    "axs[2].set_title(Path(corresponding[2]).parts[-1])\n",
    "axs[2].set_xlabel('Time')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listen to the audio samples\n",
    "for fp in corresponding:\n",
    "    print(fp)\n",
    "    audio, sr = librosa.core.load(fp, sr= config['sr'], duration=config['sample_length'], offset=config['offset'])\n",
    "    ipd.display(ipd.Audio(audio, rate=config['sr']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Spectograms of the 3 corresponding Audiofiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating spectograms\n",
    "\n",
    "# setup subplot \n",
    "nrows, ncols = 3, 2\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(14, 10))\n",
    "\n",
    "# plot some audio waveforms\n",
    "for i, fp in enumerate(corresponding):\n",
    "    audio, sr = librosa.core.load(fp, sr=config['sr'], duration=config['sample_length'], offset=config['offset'])\n",
    "\n",
    "    # calculate stft\n",
    "    stft = librosa.stft(audio, n_fft=config['n_fft'], hop_length=config['hop_length'], win_length=config['win_length'])\n",
    "    \n",
    "    # calculate melspec\n",
    "    melspec = librosa.feature.melspectrogram(y=audio, n_fft=config['n_fft'], hop_length=config['hop_length'], win_length=config['win_length'], n_mels=config['n_mels'], fmax=int(config['sr']/2))\n",
    "    melspec = librosa.amplitude_to_db(melspec, ref=np.max)\n",
    "\n",
    "    # calculate magnitude and scale to dB\n",
    "    magspec = librosa.amplitude_to_db(np.abs(stft), ref=np.max)\n",
    "\n",
    "    # plot with librosa\n",
    "    librosa.display.specshow(magspec, x_axis='time', y_axis='linear', sr=sr, hop_length=config['hop_length'], ax=ax[i][0])\n",
    "    librosa.display.specshow(melspec, x_axis='time', y_axis='mel', sr=sr, hop_length=config['hop_length'], ax=ax[i][1])\n",
    "    \n",
    "    # adjustments\n",
    "    # ax[i][1].set_yticks([])\n",
    "    ax[i][1].set_ylabel(Path(fp).parts[-1:], rotation=270, labelpad=20)\n",
    "    ax[i][1].yaxis.set_label_position(\"right\")\n",
    "    \n",
    "    # settings for all axises but bottom ones\n",
    "    if not i == len(corresponding) - 1:\n",
    "        ax[i][0].set_xticks([])\n",
    "        ax[i][1].set_xticks([])\n",
    "        ax[i][0].set_xlabel('')\n",
    "        ax[i][1].set_xlabel('')\n",
    "    \n",
    "    # settings for upper axises\n",
    "    if i == 0:\n",
    "        ax[i][0].set_title('STFT')\n",
    "        ax[i][1].set_title('Mel Spectrogram')   \n",
    "\n",
    "# adjust whitespace in between subplots        \n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.15)\n",
    "\n",
    "print('Melspec shape: %s' % (str(melspec.shape)))\n",
    "print('Stft shape: %s' % (str(stft.shape)))\n",
    "print(f'Total data points in mel-spectrogram: {melspec.shape[0]*melspec.shape[1]}')\n",
    "print(f'Total data points in stft-spectrogram: {stft.shape[0]*stft.shape[1]}')\n",
    "print(f'-> Data Reduction by factor: {(stft.shape[0]*stft.shape[1]) / (melspec.shape[0]*melspec.shape[1])}')\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot random files wav from dataset (voicefixer files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all pathnames saved in data dict\n",
    "keys = ['path_voicefixer']\n",
    "fps = list(map(data.get, keys))\n",
    "# nested list to flat list\n",
    "fps = list(np.concatenate(fps))\n",
    "#pprint.pprint(fps, depth=2)\n",
    "\n",
    "# Plot Audiofiles\n",
    "fps_random = []\n",
    "\n",
    "# setup subplot \n",
    "nrows, ncols = 2, 2\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, 6))\n",
    "\n",
    "# plot some audio waveforms\n",
    "for r in range(nrows):\n",
    "    for c in range(ncols):\n",
    "        fp_random = fps[np.random.randint(len(fps))]\n",
    "        audio, sr = librosa.core.load(fp_random, sr= config['sr'], duration=config['sample_length'])\n",
    "        ax[r][c].plot(audio, c='k')\n",
    "        # ax[r][c].axis('off')\n",
    "        ax[r][c].set_title(Path(fp_random).parts[-1])\n",
    "        if r == 0:\n",
    "            ax[r][c].set_xticks([])\n",
    "        # save random audio filepaths\n",
    "        fps_random.append(fp_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listen to the audio samples\n",
    "for fp in fps_random:\n",
    "    print(fp)\n",
    "    audio, sr = librosa.core.load(fp, sr= config['sr'], duration=config['sample_length'], offset=config['offset'])\n",
    "    ipd.display(ipd.Audio(audio, rate=config['sr']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Masterarbeit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8d3b83eb42bfd4da892e611d8844a830b4077794ee675292fead045604e9567"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
