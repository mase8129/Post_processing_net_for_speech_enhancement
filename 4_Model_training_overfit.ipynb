{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tfrecords, define model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.9.1\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "GPU not available :(\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "\n",
    " # TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "print('Tensorflow Version:', tf.__version__)\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "#Tensorboard\n",
    "%load_ext tensorboard\n",
    "\n",
    "\n",
    "# Helper libraries\n",
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "import librosa\n",
    "import librosa.display\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import IPython.display as pd\n",
    "import pprint\n",
    "import datetime        \n",
    "from scipy.io.wavfile import write\n",
    "import random\n",
    "\n",
    "\n",
    "# Check if the GPU is available (otherwise computing will take a looooonnnnggggg time)\n",
    "print(\"GPU\", \"available (YESS!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load global settings in config-dictionary\n",
    "with open('./MA_CONFIG.json', 'r') as fp:\n",
    "  config = json.load(fp)\n",
    "\n",
    "# define some extra values\n",
    "config['batch_size'] = 16\n",
    "config['shuffle_buffer_size'] = 300\n",
    "\n",
    "# print config\n",
    "#print(json.dumps(config, indent=4))\n",
    "\n",
    "# save config to disk\n",
    "with open('./MA_CONFIG.json', 'w+') as fp:\n",
    "    json.dump(config, fp, sort_keys=True, indent=4)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funcs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autotune for performance\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# decode tfrecords\n",
    "def decode_tf_records(seralized_example):\n",
    "    feature_description = {\n",
    "        \"voicefixer\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"produced\": tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(seralized_example, feature_description)\n",
    "\n",
    "    voicefixer, _ = tf.audio.decode_wav(example[\"voicefixer\"], desired_channels=-1)\n",
    "    produced, _ = tf.audio.decode_wav(example[\"produced\"], desired_channels=-1)\n",
    "    \n",
    "    return voicefixer, produced\n",
    "\n",
    "\n",
    "def slicing_audio(voicefixer, produced):\n",
    "    # generate random integer between 0 and 10*44100-3*44100\n",
    "    random_int = tf.random.uniform(shape=[], minval=0, maxval=7*44100, dtype=tf.int32)\n",
    "    # slice audio\n",
    "    voicefixer = voicefixer[random_int:random_int+3*44100]\n",
    "    produced = produced[random_int:random_int+3*44100]\n",
    "    return voicefixer, produced\n",
    " \n",
    "\n",
    "#--------------------------------------------\n",
    "# helper func\n",
    "def float2pcm(sig, dtype='int16'):\n",
    "    sig = np.asarray(sig)\n",
    "    if sig.dtype.kind != 'f':\n",
    "        raise TypeError(\"'sig' must be a float array\")\n",
    "    dtype = np.dtype(dtype)\n",
    "    if dtype.kind not in 'iu':\n",
    "        raise TypeError(\"'dtype' must be an integer type\")\n",
    "\n",
    "    i = np.iinfo(dtype)\n",
    "    abs_max = 2 ** (i.bits - 1)\n",
    "    offset = i.min + abs_max\n",
    "    return (sig * abs_max + offset).clip(i.min, i.max).astype(dtype)\n",
    "\n",
    "\n",
    "#--------------------------------------------\n",
    "# get audiofile from dataset and use as input for prediction\n",
    "def set_speechfile(test_dataset, log_dir):\n",
    "\n",
    "\n",
    "    dataset = test_dataset.unbatch().as_numpy_iterator()\n",
    "    speech_for_predicition = []\n",
    "    for i, sample in enumerate(dataset):\n",
    "        speech_for_predicition.append(sample[0])\n",
    "        break\n",
    "    # # normalize speechfile\n",
    "    speech_for_predicition = speech_for_predicition[0]\n",
    "    speech_for_predicition = librosa.util.normalize(speech_for_predicition)\n",
    "    \n",
    "    # save speech file used for prediction\n",
    "    # save plot to disk\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    x = np.arange(0, len(speech_for_predicition)/44100, 1/44100)\n",
    "    plt.plot(x, speech_for_predicition)\n",
    "    plt.title('Speechfile used for prediction')\n",
    "    plt.xlabel('Time in s')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.savefig(log_dir + '/_audiofile_for_prediction.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # save audiofile to disk\n",
    "    write(log_dir + '/_audiofile_for_prediction' + '.wav', int(44100), float2pcm(speech_for_predicition))\n",
    "   \n",
    "    return speech_for_predicition\n",
    "\n",
    "\n",
    "#--------------------------------------------\n",
    "# save audio files from logs to tf.summary.audio and event files for tensorboard\n",
    "def save_audio_to_summaries(log_dir):\n",
    "    \n",
    "        # get audio files from logs\n",
    "        fps = glob.glob(log_dir + '/*.wav')\n",
    "        path_audiosummary = log_dir + '/audiosummary/'\n",
    "\n",
    "        # for each audio file\n",
    "        for idx, fp in enumerate(fps):\n",
    "            \n",
    "            # write audiosummary of one audio file to disk\n",
    "             writer = tf.summary.create_file_writer(path_audiosummary)\n",
    "             with writer.as_default():\n",
    "                \n",
    "                # load audio file as tensor\n",
    "                file = tf.io.read_file(fp)\n",
    "                audio = tf.audio.decode_wav(file, desired_channels=1)\n",
    "\n",
    "                # write audio file to tf.summary.audio\n",
    "                name = fp.split('/')[-1]\n",
    "                tf.summary.audio(name , tf.expand_dims(audio[0], 0), int(44100), step=idx)\n",
    "                writer.flush()\n",
    "\n",
    "\n",
    "#--------------------------------------------\n",
    "import tensorflow as tf\n",
    "class TFSpectralConvergence(tf.keras.layers.Layer):\n",
    "    \"\"\"Spectral convergence loss.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_mag, x_mag):\n",
    "        \"\"\"Calculate forward propagation.\n",
    "        Args:\n",
    "            y_mag (Tensor): Magnitude spectrogram of groundtruth signal (B, #frames, #freq_bins).\n",
    "            x_mag (Tensor): Magnitude spectrogram of predicted signal (B, #frames, #freq_bins).\n",
    "        Returns:\n",
    "            Tensor: Spectral convergence loss value.\n",
    "        \"\"\"\n",
    "        return tf.norm(y_mag - x_mag, ord=\"fro\", axis=(-2, -1)) / tf.norm(y_mag, ord=\"fro\", axis=(-2, -1))\n",
    "\n",
    "\n",
    "class TFLogSTFTMagnitude(tf.keras.layers.Layer):\n",
    "    \"\"\"Log STFT magnitude loss module.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, y_mag, x_mag):\n",
    "        \"\"\"Calculate forward propagation.\n",
    "        Args:\n",
    "            y_mag (Tensor): Magnitude spectrogram of groundtruth signal (B, #frames, #freq_bins).\n",
    "            x_mag (Tensor): Magnitude spectrogram of predicted signal (B, #frames, #freq_bins).\n",
    "        Returns:\n",
    "            Tensor: Spectral convergence loss value.\n",
    "        \"\"\"\n",
    "        return tf.abs(tf.math.log(y_mag) - tf.math.log(x_mag))\n",
    "\n",
    "\n",
    "class TFSTFT(tf.keras.layers.Layer):\n",
    "    \"\"\"STFT loss module.\"\"\"\n",
    "\n",
    "    def __init__(self, frame_length=600, frame_step=120, fft_length=1024):\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super().__init__()\n",
    "        self.frame_length = frame_length\n",
    "        self.frame_step = frame_step\n",
    "        self.fft_length = fft_length\n",
    "        self.spectral_convergenge_loss = TFSpectralConvergence()\n",
    "        self.log_stft_magnitude_loss = TFLogSTFTMagnitude()\n",
    "\n",
    "    def call(self, y, x):\n",
    "        \"\"\"Calculate forward propagation.\n",
    "        Args:\n",
    "            y (Tensor): Groundtruth signal (B, T).\n",
    "            x (Tensor): Predicted signal (B, T).\n",
    "        Returns:\n",
    "            Tensor: Spectral convergence loss value (pre-reduce).\n",
    "            Tensor: Log STFT magnitude loss value (pre-reduce).\n",
    "        \"\"\"\n",
    "\n",
    "        x = tf.transpose(x, perm=[0, 2, 1])\n",
    "        y = tf.transpose(y, perm=[0, 2, 1])        \n",
    "\n",
    "        x_mag = tf.abs(tf.signal.stft(signals=x,\n",
    "                                      frame_length=self.frame_length,\n",
    "                                      frame_step=self.frame_step,\n",
    "                                      fft_length=self.fft_length))\n",
    "        y_mag = tf.abs(tf.signal.stft(signals=y,\n",
    "                                      frame_length=self.frame_length,\n",
    "                                      frame_step=self.frame_step,\n",
    "                                      fft_length=self.fft_length))\n",
    "\n",
    "        # add small number to prevent nan value.\n",
    "        # compatible with pytorch version.\n",
    "        x_mag = tf.math.sqrt(x_mag ** 2 + 1e-7)\n",
    "        y_mag = tf.math.sqrt(y_mag ** 2 + 1e-7)\n",
    "\n",
    "        sc_loss = self.spectral_convergenge_loss(y_mag, x_mag)\n",
    "        mag_loss = self.log_stft_magnitude_loss(y_mag, x_mag)\n",
    "\n",
    "        return sc_loss, mag_loss\n",
    "    \n",
    "    \n",
    "class TFMultiResolutionSTFT(tf.keras.layers.Layer):\n",
    "    \"\"\"Multi resolution STFT loss module.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 fft_lengths=[1024, 2048, 512],\n",
    "                 frame_lengths=[600, 1200, 240],\n",
    "                 frame_steps=[120, 240, 50],):\n",
    "        \"\"\"Initialize Multi resolution STFT loss module.\n",
    "        Args:\n",
    "            frame_lengths (list): List of FFT sizes.\n",
    "            frame_steps (list): List of hop sizes.\n",
    "            fft_lengths (list): List of window lengths.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        assert len(frame_lengths) == len(frame_steps) == len(fft_lengths)\n",
    "        self.stft_losses = []\n",
    "        for frame_length, frame_step, fft_length in zip(frame_lengths, frame_steps, fft_lengths):\n",
    "            self.stft_losses.append(TFSTFT(frame_length, frame_step, fft_length))\n",
    "\n",
    "    def call(self, y, x):\n",
    "        \"\"\"Calculate forward propagation.\n",
    "        Args:\n",
    "            y (Tensor): Groundtruth signal (B, T).\n",
    "            x (Tensor): Predicted signal (B, T).\n",
    "        Returns:\n",
    "            Tensor: Multi resolution spectral convergence loss value.\n",
    "            Tensor: Multi resolution log STFT magnitude loss value.\n",
    "        \"\"\"\n",
    "        sc_loss = 0.0\n",
    "        mag_loss = 0.0\n",
    "        for f in self.stft_losses:\n",
    "            sc_l, mag_l = f(y, x)\n",
    "            sc_loss += tf.reduce_mean(sc_l)\n",
    "            mag_loss += tf.reduce_mean(mag_l)\n",
    "\n",
    "        sc_loss /= len(self.stft_losses)\n",
    "        mag_loss /= len(self.stft_losses)\n",
    "\n",
    "        return mag_loss\n",
    "\n",
    "\n",
    "class CustomLoss(tf.keras.losses.Loss):\n",
    "    \"\"\"custom loss calculated from MAE and Multiresolution STFT loss\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mae = tf.keras.losses.MeanAbsoluteError()\n",
    "        self.stft = TFMultiResolutionSTFT()\n",
    "\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        mae = self.mae(y_true, y_pred)\n",
    "        stft = self.stft(y_true, y_pred)\n",
    "        #return ((mae+stft) / 2)\n",
    "        return (mae)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if losses work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# loss1 = TFMultiResolutionSTFT()\n",
    "# loss2 = tf.keras.losses.MeanAbsoluteError()\n",
    "# loss3 = CustomLoss()\n",
    "\n",
    "\n",
    "# # load train tfrecords\n",
    "# path = glob.glob('/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Dataset/train_tfrecords/*.tfrecords')\n",
    "# DS = tf.data.TFRecordDataset(path[:5])\n",
    "# DS = DS.map(decode_tf_records, num_parallel_calls=AUTOTUNE)\n",
    "# DS = DS.map(slicing_audio, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "\n",
    "# sf = []\n",
    "# label = []\n",
    "\n",
    "# for y, X in DS.take(10):\n",
    "#   print(y.numpy().shape, X.numpy().shape)\n",
    "#   sf.append(y.numpy().T)\n",
    "#   label.append(X.numpy().T)\n",
    "\n",
    "# print(sf[0].shape)\n",
    "\n",
    "# # # transpose \n",
    "# # file = tf.transpose(sf[0])\n",
    "# # file2 = sf[0].T\n",
    "\n",
    "# # print(file.shape)\n",
    "# # print(file2.shape)\n",
    "\n",
    "\n",
    "# # plot waveform\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(10, 4))\n",
    "# plt.subplot(2, 1, 1)     \n",
    "# plt.title('voicefixer')\n",
    "# plt.plot(sf[0].T)\n",
    "# plt.subplot(2, 1, 2)\n",
    "# plt.title('Label')\n",
    "# plt.plot(label[0].T)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(len(sf)):\n",
    "#   print(f'Stft loss is:{loss1(label[i], sf[i])}')\n",
    "#   print(f'MAE loss is:{loss2(label[i], sf[i])}')\n",
    "#   print(f'custom loss is:{loss3(label[i], sf[i])}')\n",
    "#   print('-------------------')\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in train_dataset: 600\n"
     ]
    }
   ],
   "source": [
    "# load train tfrecords\n",
    "tfrecords_paths = glob.glob('/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Dataset/train_tfrecords/*.tfrecords')\n",
    "train_dataset = tf.data.TFRecordDataset(tfrecords_paths[:10])\n",
    "#train_dataset = train_dataset.take(1)\n",
    "train_dataset = train_dataset.map(decode_tf_records, num_parallel_calls=AUTOTUNE)\n",
    "train_dataset = train_dataset.map(slicing_audio, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# count elements in train_dataset\n",
    "print(f'Number of elements in train_dataset: {len([d for d in train_dataset])}')\n",
    "\n",
    "# batching and shuffling\n",
    "train_dataset = train_dataset.shuffle(config['shuffle_buffer_size']).batch(config['batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-24 16:47:21.926623: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in test_dataset: 300\n"
     ]
    }
   ],
   "source": [
    "# load test tfrecords\n",
    "tfrecords_paths = glob.glob('/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Dataset/test_tfrecords/*.tfrecords')\n",
    "test_dataset = tf.data.TFRecordDataset(tfrecords_paths[:5])\n",
    "#test_dataset = test_dataset.take(1)\n",
    "\n",
    "test_dataset = test_dataset.map(decode_tf_records, num_parallel_calls=AUTOTUNE)\n",
    "test_dataset = test_dataset.map(slicing_audio, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# count elements in test_dataset\n",
    "print(f'Number of elements in test_dataset: {len([d for d in test_dataset])}')\n",
    "\n",
    "# batching and shuffling\n",
    "test_dataset = test_dataset.shuffle(config['shuffle_buffer_size']).batch(config['batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 132300, 1)\n",
      "(16, 132300, 1)\n",
      "(16, 132300, 1)\n",
      "(16, 132300, 1)\n"
     ]
    }
   ],
   "source": [
    "# check if datasets are loaded correctly\n",
    "for d in train_dataset:\n",
    "    print(d[0].shape)\n",
    "    print(d[1].shape)\n",
    "    break   \n",
    "\n",
    "for d in test_dataset:\n",
    "    print(d[0].shape)\n",
    "    print(d[1].shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some values for training\n",
    "config['n_epochs'] = 20\n",
    "config['learning_rate'] = 0.002\n",
    "# Filter:Kernel = 4:1 (see hifi-gan paper)\n",
    "config['filter_size'] = 64\n",
    "config['kernel_size'] = 5\n",
    "config['activation_func'] = 'tanh'\n",
    "\n",
    "\n",
    "# save config to disk\n",
    "with open('./MA_CONFIG.json', 'w+') as fp:\n",
    "    json.dump(config, fp, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some values for the model\n",
    "input_shape = (3*44100, 1)\n",
    "output_channels = 1\n",
    "\n",
    "\n",
    "# build model with 12 layers\n",
    "def build_model(input_shape):\n",
    "\n",
    "    # define model\n",
    "    model = keras.Sequential(name='PostNet_Conv1D')\n",
    "    model.add(keras.Input(shape=input_shape))\n",
    "\n",
    "    # add layer \n",
    "    model.add(keras.layers.Conv1D(filters=config['filter_size'], kernel_size=config['kernel_size'], padding='same'))\n",
    "    # add dropout layer, batch normalization and activation layer\n",
    "    #model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(config['activation_func']))\n",
    "\n",
    "    # Add the remaining Conv1D layers\n",
    "    for _ in range(1):\n",
    "        model.add(keras.layers.Conv1D(filters=config['filter_size'], kernel_size=config['kernel_size'], padding='same'))\n",
    "        # add dropout layer, batch normalization and activation layer\n",
    "        #model.add(keras.layers.BatchNormalization())\n",
    "        model.add(keras.layers.Activation(config['activation_func']))\n",
    "\n",
    "    # Add the final Conv1D layer without activation layer\n",
    "    model.add(keras.layers.Conv1D(filters=output_channels, kernel_size=1, padding='same'))\n",
    "    #model.add(keras.layers.BatchNormalization())\n",
    "    #model.add(keras.layers.Activation(config['activation_func']))\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"PostNet_Conv1D\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_118 (Conv1D)         (None, 132300, 64)        384       \n",
      "                                                                 \n",
      " activation_111 (Activation)  (None, 132300, 64)       0         \n",
      "                                                                 \n",
      " conv1d_119 (Conv1D)         (None, 132300, 64)        20544     \n",
      "                                                                 \n",
      " activation_112 (Activation)  (None, 132300, 64)       0         \n",
      "                                                                 \n",
      " conv1d_120 (Conv1D)         (None, 132300, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,993\n",
      "Trainable params: 20,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# initialize log_dir\n",
    "log_dir = \"./logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# make directory if not exist\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "\n",
    "#--------------------------------------------\n",
    "# define callbacks\n",
    "\n",
    "save_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath='./model_checkpoint',\n",
    "    save_best_only=False,\n",
    "    monitor='val_loss',\n",
    "    verbose=0)\n",
    "\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "    log_dir= log_dir,\n",
    "    histogram_freq=1,\n",
    "    write_graph=True,\n",
    "    write_images=True,\n",
    "    write_steps_per_second=True,\n",
    "    update_freq='epoch',\n",
    "    profile_batch=0,\n",
    "    embeddings_freq=1)\n",
    "\n",
    "# early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "#     monitor='val_loss',\n",
    "#     patience=5,\n",
    "#     verbose=1)\n",
    "\n",
    "\n",
    "# get speechfile for prediction\n",
    "speech_for_predicition = set_speechfile(test_dataset, log_dir)\n",
    "\n",
    "#--------------------------------------------\n",
    "# define custom callback\n",
    "class CustomCallback(keras.callbacks.Callback):\n",
    "     \n",
    "    # define functions to happen during training after each epoch\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        # save predicted audio file after each epoch to disk\n",
    "        # get audio file from model prediciton\n",
    "        audio = self.model.predict(speech_for_predicition)\n",
    "\n",
    "        # change shape to (len(audio), 1)\n",
    "        audio = tf.squeeze(audio, axis=-1)\n",
    "        audio = tf.squeeze(audio, axis=-1).numpy()\n",
    "        #print(audio.shape)\n",
    "\n",
    "        # normalize audio with numpy\n",
    "        #audio = librosa.util.normalize(audio).astype(np.float32)\n",
    "        audio = audio.astype(np.float32)\n",
    "\n",
    "        # save plot to disk\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        x = np.arange(0, len(audio)/44100, 1/44100)\n",
    "        plt.plot(x, audio)\n",
    "        plt.title('Audiofile')\n",
    "        plt.xlabel('Time in s')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.savefig(log_dir + '/_audiofile_epoch' + str(epoch+1) + '.png')\n",
    "        plt.close()\n",
    "\n",
    "        # write audio file to disk (16-bit PCM WAV)\n",
    "        write(log_dir + '/_audiofile_epoch' + str(epoch+1) + '.wav', 44100, float2pcm(audio))\n",
    "\n",
    "\n",
    "#--------------------------------------------\n",
    "# get model\n",
    "model = build_model(input_shape = input_shape)\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer = keras.optimizers.Adam(learning_rate=config['learning_rate']),\n",
    "              loss = tf.keras.losses.MeanSquaredError(),\n",
    "              metrics = tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Clear any logs from previous runs\n",
    "# !rm -rf ./logs/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fit and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     38/Unknown - 111s 3s/step - loss: 0.0213 - mean_squared_error: 0.0213"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 132300, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 132300, 1), dtype=tf.float32, name='input_19'), name='input_19', description=\"created by layer 'input_19'\"), but it was called on an input with incompatible shape (None, 1, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 132300, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 132300, 1), dtype=tf.float32, name='input_19'), name='input_19', description=\"created by layer 'input_19'\"), but it was called on an input with incompatible shape (None, 1, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4135/4135 [==============================] - 2s 471us/step\n",
      "38/38 [==============================] - 130s 3s/step - loss: 0.0213 - mean_squared_error: 0.0213 - val_loss: 0.0162 - val_mean_squared_error: 0.0161\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0211 - mean_squared_error: 0.0210"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4135/4135 [==============================] - 2s 482us/step\n",
      "38/38 [==============================] - 129s 3s/step - loss: 0.0211 - mean_squared_error: 0.0210 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0216 - mean_squared_error: 0.0216"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4135/4135 [==============================] - 2s 466us/step\n",
      "38/38 [==============================] - 126s 3s/step - loss: 0.0216 - mean_squared_error: 0.0216 - val_loss: 0.0156 - val_mean_squared_error: 0.0157\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0207 - mean_squared_error: 0.0207"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4135/4135 [==============================] - 2s 461us/step\n",
      "38/38 [==============================] - 123s 3s/step - loss: 0.0207 - mean_squared_error: 0.0207 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0203 - mean_squared_error: 0.0203"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4135/4135 [==============================] - 2s 456us/step\n",
      "38/38 [==============================] - 126s 3s/step - loss: 0.0203 - mean_squared_error: 0.0203 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0207 - mean_squared_error: 0.0207"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4135/4135 [==============================] - 2s 465us/step\n",
      "38/38 [==============================] - 125s 3s/step - loss: 0.0207 - mean_squared_error: 0.0207 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0211 - mean_squared_error: 0.0211"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4135/4135 [==============================] - 2s 471us/step\n",
      "38/38 [==============================] - 126s 3s/step - loss: 0.0211 - mean_squared_error: 0.0211 - val_loss: 0.0160 - val_mean_squared_error: 0.0159\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0214 - mean_squared_error: 0.0214"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4135/4135 [==============================] - 2s 490us/step\n",
      "38/38 [==============================] - 127s 3s/step - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.0164 - val_mean_squared_error: 0.0163\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0210 - mean_squared_error: 0.0211"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4135/4135 [==============================] - 2s 457us/step\n",
      "38/38 [==============================] - 129s 3s/step - loss: 0.0210 - mean_squared_error: 0.0211 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.0211 - mean_squared_error: 0.0211"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model_checkpoint/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4135/4135 [==============================] - 2s 454us/step\n",
      "38/38 [==============================] - 127s 3s/step - loss: 0.0211 - mean_squared_error: 0.0211 - val_loss: 0.0164 - val_mean_squared_error: 0.0165\n",
      "Epoch 11/20\n",
      " 9/38 [======>.......................] - ETA: 1:22 - loss: 0.0214 - mean_squared_error: 0.0214"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Post_processing_net_for_speech_enhancement/4_Model_training_overfit.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Post_processing_net_for_speech_enhancement/4_Model_training_overfit.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# fit model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Post_processing_net_for_speech_enhancement/4_Model_training_overfit.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_dataset,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Post_processing_net_for_speech_enhancement/4_Model_training_overfit.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49mconfig[\u001b[39m'\u001b[39;49m\u001b[39mn_epochs\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Post_processing_net_for_speech_enhancement/4_Model_training_overfit.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49mtest_dataset,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Post_processing_net_for_speech_enhancement/4_Model_training_overfit.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                     callbacks\u001b[39m=\u001b[39;49m[save_callback, tensorboard_callback, CustomCallback()])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Post_processing_net_for_speech_enhancement/4_Model_training_overfit.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# save model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Post_processing_net_for_speech_enhancement/4_Model_training_overfit.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39m./model.keras\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Masterarbeit/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Masterarbeit/lib/python3.9/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Masterarbeit/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Masterarbeit/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Masterarbeit/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Masterarbeit/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Masterarbeit/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Masterarbeit/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Masterarbeit/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=config['n_epochs'],\n",
    "                    validation_data=test_dataset,\n",
    "                    callbacks=[save_callback, tensorboard_callback, CustomCallback()])\n",
    "\n",
    "# save model\n",
    "model.save('./model.keras')\n",
    "\n",
    "# save history\n",
    "with open('./history.json', 'w+') as fp:\n",
    "    json.dump(history.history, fp, sort_keys=True, indent=4)\n",
    "\n",
    "\n",
    "# call def to save audio to summaries\n",
    "save_audio_to_summaries(log_dir)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check history and simple plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mean_squared_error', 'val_loss', 'val_mean_squared_error'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'mean_absolute_error'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Post_processing_net_for_speech_enhancement/4_Model_training_overfit.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Post_processing_net_for_speech_enhancement/4_Model_training_overfit.ipynb#X30sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m train_loss \u001b[39m=\u001b[39m history[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Post_processing_net_for_speech_enhancement/4_Model_training_overfit.ipynb#X30sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m eval_loss \u001b[39m=\u001b[39m history[\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Post_processing_net_for_speech_enhancement/4_Model_training_overfit.ipynb#X30sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m mae \u001b[39m=\u001b[39m history[\u001b[39m'\u001b[39;49m\u001b[39mmean_absolute_error\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Post_processing_net_for_speech_enhancement/4_Model_training_overfit.ipynb#X30sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m val_mae \u001b[39m=\u001b[39m history[\u001b[39m'\u001b[39m\u001b[39mval_mean_absolute_error\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/marius/Documents/Uni/TU_Berlin_Master/Masterarbeit/Post_processing_net_for_speech_enhancement/4_Model_training_overfit.ipynb#X30sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m fig2 \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure()\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mean_absolute_error'"
     ]
    }
   ],
   "source": [
    "# open history\n",
    "with open('./history.json', 'r') as fp:\n",
    "  history = json.load(fp)\n",
    "\n",
    "# check out history keys\n",
    "print(history.keys())\n",
    "\n",
    "# simple plot losses\n",
    "train_loss = history['loss']\n",
    "eval_loss = history['val_loss']\n",
    "mae = history['mean_absolute_error']\n",
    "val_mae = history['val_mean_absolute_error']\n",
    "\n",
    "\n",
    "\n",
    "fig2 = plt.figure()\n",
    "plt.plot(range(config['n_epochs']), train_loss, label='train')\n",
    "plt.plot(range(config['n_epochs']), eval_loss, label='eval')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Custom Loss')\n",
    "plt.title('Training with ' \n",
    "                           + str(config['n_epochs'])\n",
    "                           + ' epochs \\n batch-size: '\n",
    "                           + str(config['batch_size']))\n",
    "                     \n",
    "plt.show()  \n",
    "\n",
    "\n",
    "fig3 = plt.figure()\n",
    "plt.plot(range(config['n_epochs']), mae, label='train')\n",
    "plt.plot(range(config['n_epochs']), val_mae, label='eval')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE Loss')\n",
    "plt.title('Training with ' \n",
    "                           + str(config['n_epochs'])\n",
    "                           + ' epochs \\n batch-size: '\n",
    "                           + str(config['batch_size']))\n",
    "                     \n",
    "plt.show()  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-702b39c2841812d3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-702b39c2841812d3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model from disk and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 132300, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 132300, 1), dtype=tf.float32, name='input_11'), name='input_11', description=\"created by layer 'input_11'\"), but it was called on an input with incompatible shape (None, 1, 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 132300, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 132300, 1), dtype=tf.float32, name='input_11'), name='input_11', description=\"created by layer 'input_11'\"), but it was called on an input with incompatible shape (None, 1, 1).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4135/4135 [==============================] - 5s 1ms/step\n",
      "<dtype: 'float32'>\n",
      "(132300,)\n"
     ]
    }
   ],
   "source": [
    "# # load model\n",
    "reconstructed_model = keras.models.load_model('./model.keras', compile=False)\n",
    "#reconstructed_model.summary()\n",
    "\n",
    "# get audio file from model prediciton\n",
    "audio = reconstructed_model.predict(speech_for_predicition)\n",
    "\n",
    "\n",
    "\n",
    "# change shape to (len(audio), 1)\n",
    "audio = tf.squeeze(audio, axis=-1)\n",
    "audio = tf.squeeze(audio, axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "print(audio.dtype)\n",
    "print(audio.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0. 0. 0. ... 0. 0. 0.], shape=(132300,), dtype=float32)\n",
      "tf.Tensor([nan nan nan ... nan nan nan], shape=(132300,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(audio)\n",
    "\n",
    "# normalize audio with numpy\n",
    "# audio = librosa.util.normalize(audio)\n",
    "\n",
    "# normalize audio with tensorflow\n",
    "audio = tf.math.divide(audio, tf.math.reduce_max(audio))\n",
    "print(audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# save plot to disk\n",
    "plt.figure(figsize=(8, 4))\n",
    "x = np.arange(0, len(audio)/44100, 1/44100)\n",
    "plt.plot(x, audio)\n",
    "plt.title('Audiofile')\n",
    "plt.xlabel('Time in s')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.savefig(log_dir + '/_audiofile_Reconstructed_model..png')\n",
    "plt.show()\n",
    "\n",
    "# write audio file to disk (16-bit PCM WAV)\n",
    "write(log_dir + '/_audiofile_Reconstructed_model.wav', 44100, audio.numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # look at some example data from train dataset\n",
    "# wavs = train_dataset.unbatch().as_numpy_iterator()\n",
    "# noisy = []\n",
    "# gt = []\n",
    "\n",
    "# # Setup Subplot\n",
    "# nrows, ncols = 2, 2\n",
    "# fig, ax = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, figsize=(16, 9))\n",
    "\n",
    "\n",
    "# # iterate over dataset\n",
    "# for i, sample in enumerate(wavs):\n",
    "    \n",
    "#     # get the column and row by modulo and remainder\n",
    "#     j = i % ncols\n",
    "#     k = int(i / ncols)\n",
    "    \n",
    "#     # extract noisy and produced speech file from tensors\n",
    "#     wave = sample[0]\n",
    "#     ground_truth = sample[1]\n",
    "        \n",
    "#     # plot files\n",
    "#     librosa.display.waveshow(np.squeeze(wave), x_axis='time', sr=config['sr'], ax=ax[k][j], label='test_file')\n",
    "#     librosa.display.waveshow(np.squeeze(ground_truth), alpha=0.3, x_axis='time', sr=config['sr'], ax=ax[k][j], label='ground_truth')\n",
    "#     ax[k][j].legend()\n",
    "#     ax[k][j].axis('on')\n",
    "#     ax[k][j].set_title('10s speech')  \n",
    "\n",
    "#     # save speech to arrays\n",
    "#     noisy.append(np.squeeze(wave))\n",
    "#     gt.append(np.squeeze(ground_truth))\n",
    "    \n",
    "#     if i+1 == ncols*nrows:\n",
    "#         break\n",
    "    \n",
    "# # adjust whitespace in between subplots        \n",
    "# plt.subplots_adjust(hspace=0.25, wspace=0.15)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # listen to the audio samples\n",
    "# for i in range(len(gt)):\n",
    "#     print(f'----------- {i+1}. speechsnippet ---------------')\n",
    "#     print('')\n",
    "#     print(f'Voicefixer file')\n",
    "#     pd.display(pd.Audio(noisy[i].T, rate=config['sr']))\n",
    "#     print(f'corresponding produced file')\n",
    "#     pd.display(pd.Audio(gt[i].T, rate=config['sr']))\n",
    "#     print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Masterarbeit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
